{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary EDA on US Youtube Trending Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ignoring warnings that pop up during execution\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap in /home/aditya/anaconda3/lib/python3.8/site-packages (0.1.1)\n",
      "Requirement already satisfied: missingno in /home/aditya/anaconda3/lib/python3.8/site-packages (0.4.2)\n",
      "Requirement already satisfied: matplotlib in /home/aditya/anaconda3/lib/python3.8/site-packages (from missingno) (3.2.2)\n",
      "Requirement already satisfied: numpy in /home/aditya/anaconda3/lib/python3.8/site-packages (from missingno) (1.18.5)\n",
      "Requirement already satisfied: seaborn in /home/aditya/anaconda3/lib/python3.8/site-packages (from missingno) (0.10.1)\n",
      "Requirement already satisfied: scipy in /home/aditya/anaconda3/lib/python3.8/site-packages (from missingno) (1.5.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aditya/anaconda3/lib/python3.8/site-packages (from matplotlib->missingno) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from matplotlib->missingno) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from matplotlib->missingno) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from matplotlib->missingno) (2.8.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from seaborn->missingno) (1.0.5)\n",
      "Requirement already satisfied: six in /home/aditya/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->missingno) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pandas>=0.22.0->seaborn->missingno) (2020.1)\n",
      "Requirement already satisfied: rake_nltk in /home/aditya/anaconda3/lib/python3.8/site-packages (1.0.4)\n",
      "Requirement already satisfied: nltk in /home/aditya/anaconda3/lib/python3.8/site-packages (from rake_nltk) (3.5)\n",
      "Requirement already satisfied: joblib in /home/aditya/anaconda3/lib/python3.8/site-packages (from nltk->rake_nltk) (0.16.0)\n",
      "Requirement already satisfied: click in /home/aditya/anaconda3/lib/python3.8/site-packages (from nltk->rake_nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/aditya/anaconda3/lib/python3.8/site-packages (from nltk->rake_nltk) (4.47.0)\n",
      "Requirement already satisfied: regex in /home/aditya/anaconda3/lib/python3.8/site-packages (from nltk->rake_nltk) (2020.6.8)\n",
      "Requirement already satisfied: wordcloud in /home/aditya/anaconda3/lib/python3.8/site-packages (1.8.1)\n",
      "Requirement already satisfied: pillow in /home/aditya/anaconda3/lib/python3.8/site-packages (from wordcloud) (7.2.0)\n",
      "Requirement already satisfied: matplotlib in /home/aditya/anaconda3/lib/python3.8/site-packages (from wordcloud) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from wordcloud) (1.18.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aditya/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: six in /home/aditya/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n",
      "Requirement already satisfied: umap-learn in /home/aditya/anaconda3/lib/python3.8/site-packages (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/aditya/anaconda3/lib/python3.8/site-packages (from umap-learn) (1.18.5)\n",
      "Requirement already satisfied: numba!=0.47,>=0.46 in /home/aditya/anaconda3/lib/python3.8/site-packages (from umap-learn) (0.50.1)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from umap-learn) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /home/aditya/anaconda3/lib/python3.8/site-packages (from umap-learn) (0.23.1)\n",
      "Requirement already satisfied: llvmlite<0.34,>=0.33.0.dev0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from numba!=0.47,>=0.46->umap-learn) (0.33.0)\n",
      "Requirement already satisfied: setuptools in /home/aditya/anaconda3/lib/python3.8/site-packages (from numba!=0.47,>=0.46->umap-learn) (49.2.0.post20200714)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20->umap-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/aditya/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20->umap-learn) (0.16.0)\n",
      "Requirement already satisfied: datashader in /home/aditya/anaconda3/lib/python3.8/site-packages (0.11.1)\n",
      "Requirement already satisfied: xarray>=0.9.6 in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (0.16.2)\n",
      "Requirement already satisfied: bokeh in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (2.2.3)\n",
      "Requirement already satisfied: pillow>=3.1.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (7.2.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (1.18.5)\n",
      "Collecting numba!=0.49.*,!=0.50.*,>=0.37.0\n",
      "  Using cached numba-0.52.0-cp38-cp38-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Requirement already satisfied: param>=1.6.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (1.10.0)\n",
      "Requirement already satisfied: pyct[cmd]==0.4.6 in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (0.4.6)\n",
      "Requirement already satisfied: scipy in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (1.5.0)\n",
      "Requirement already satisfied: toolz>=0.7.4 in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (0.10.0)\n",
      "Requirement already satisfied: dask[complete]>=0.18.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (2.20.0)\n",
      "Requirement already satisfied: datashape>=0.5.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (0.5.2)\n",
      "Requirement already satisfied: pandas>=0.24.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (1.0.5)\n",
      "Requirement already satisfied: colorcet>=0.9.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashader) (2.0.2)\n",
      "Requirement already satisfied: setuptools>=38.4 in /home/aditya/anaconda3/lib/python3.8/site-packages (from xarray>=0.9.6->datashader) (49.2.0.post20200714)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh->datashader) (2.8.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh->datashader) (2.11.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh->datashader) (3.7.4.2)\n",
      "Requirement already satisfied: tornado>=5.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh->datashader) (6.0.4)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh->datashader) (5.3.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh->datashader) (20.4)\n",
      "Collecting llvmlite<0.36,>=0.35.0\n",
      "  Using cached llvmlite-0.35.0-cp38-cp38-manylinux2010_x86_64.whl (25.3 MB)\n",
      "Requirement already satisfied: requests; extra == \"cmd\" in /home/aditya/anaconda3/lib/python3.8/site-packages (from pyct[cmd]==0.4.6->datashader) (2.24.0)\n",
      "Requirement already satisfied: distributed>=2.0; extra == \"complete\" in /home/aditya/anaconda3/lib/python3.8/site-packages (from dask[complete]>=0.18.0->datashader) (2.20.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0; extra == \"complete\" in /home/aditya/anaconda3/lib/python3.8/site-packages (from dask[complete]>=0.18.0->datashader) (0.7.4)\n",
      "Requirement already satisfied: partd>=0.3.10; extra == \"complete\" in /home/aditya/anaconda3/lib/python3.8/site-packages (from dask[complete]>=0.18.0->datashader) (1.1.0)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2; extra == \"complete\" in /home/aditya/anaconda3/lib/python3.8/site-packages (from dask[complete]>=0.18.0->datashader) (1.5.0)\n",
      "Requirement already satisfied: multipledispatch>=0.4.7 in /home/aditya/anaconda3/lib/python3.8/site-packages (from datashape>=0.5.1->datashader) (0.6.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.1->datashader) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/aditya/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.1->bokeh->datashader) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/aditya/anaconda3/lib/python3.8/site-packages (from Jinja2>=2.7->bokeh->datashader) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from packaging>=16.8->bokeh->datashader) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/aditya/anaconda3/lib/python3.8/site-packages (from requests; extra == \"cmd\"->pyct[cmd]==0.4.6->datashader) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from requests; extra == \"cmd\"->pyct[cmd]==0.4.6->datashader) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aditya/anaconda3/lib/python3.8/site-packages (from requests; extra == \"cmd\"->pyct[cmd]==0.4.6->datashader) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from requests; extra == \"cmd\"->pyct[cmd]==0.4.6->datashader) (1.25.9)\n",
      "Requirement already satisfied: zict>=0.1.3 in /home/aditya/anaconda3/lib/python3.8/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader) (2.0.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader) (1.0.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader) (2.2.2)\n",
      "Requirement already satisfied: psutil>=5.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader) (5.7.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader) (1.6.0)\n",
      "Requirement already satisfied: click>=6.6 in /home/aditya/anaconda3/lib/python3.8/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader) (7.1.2)\n",
      "Requirement already satisfied: locket in /home/aditya/anaconda3/lib/python3.8/site-packages (from partd>=0.3.10; extra == \"complete\"->dask[complete]>=0.18.0->datashader) (0.2.0)\n",
      "Requirement already satisfied: heapdict in /home/aditya/anaconda3/lib/python3.8/site-packages (from zict>=0.1.3->distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader) (1.0.1)\n",
      "Installing collected packages: llvmlite, numba\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.33.0\n",
      "    Uninstalling llvmlite-0.33.0:\n",
      "      Successfully uninstalled llvmlite-0.33.0\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.50.1\n",
      "    Uninstalling numba-0.50.1:\n",
      "      Successfully uninstalled numba-0.50.1\n",
      "Successfully installed llvmlite-0.35.0 numba-0.52.0\n",
      "Requirement already satisfied: bokeh in /home/aditya/anaconda3/lib/python3.8/site-packages (2.2.3)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh) (5.3.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh) (6.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh) (3.7.4.2)\n",
      "Requirement already satisfied: packaging>=16.8 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh) (20.4)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh) (2.11.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh) (2.8.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh) (7.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from packaging>=16.8->bokeh) (2.4.7)\n",
      "Requirement already satisfied: six in /home/aditya/anaconda3/lib/python3.8/site-packages (from packaging>=16.8->bokeh) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/aditya/anaconda3/lib/python3.8/site-packages (from Jinja2>=2.7->bokeh) (1.1.1)\n",
      "Requirement already satisfied: holoviews in /home/aditya/anaconda3/lib/python3.8/site-packages (1.14.0)\n",
      "Requirement already satisfied: colorcet in /home/aditya/anaconda3/lib/python3.8/site-packages (from holoviews) (2.0.2)\n",
      "Requirement already satisfied: pyviz-comms>=0.7.3 in /home/aditya/anaconda3/lib/python3.8/site-packages (from holoviews) (0.7.6)\n",
      "Requirement already satisfied: numpy>=1.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from holoviews) (1.18.5)\n",
      "Requirement already satisfied: pandas in /home/aditya/anaconda3/lib/python3.8/site-packages (from holoviews) (1.0.5)\n",
      "Requirement already satisfied: panel>=0.8.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from holoviews) (0.10.2)\n",
      "Requirement already satisfied: param<2.0,>=1.9.3 in /home/aditya/anaconda3/lib/python3.8/site-packages (from holoviews) (1.10.0)\n",
      "Requirement already satisfied: pyct>=0.4.4 in /home/aditya/anaconda3/lib/python3.8/site-packages (from colorcet->holoviews) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pandas->holoviews) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pandas->holoviews) (2.8.1)\n",
      "Requirement already satisfied: tqdm in /home/aditya/anaconda3/lib/python3.8/site-packages (from panel>=0.8.0->holoviews) (4.47.0)\n",
      "Requirement already satisfied: bokeh>=2.2.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from panel>=0.8.0->holoviews) (2.2.3)\n",
      "Requirement already satisfied: requests in /home/aditya/anaconda3/lib/python3.8/site-packages (from panel>=0.8.0->holoviews) (2.24.0)\n",
      "Requirement already satisfied: markdown in /home/aditya/anaconda3/lib/python3.8/site-packages (from panel>=0.8.0->holoviews) (3.3.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/aditya/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas->holoviews) (1.15.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh>=2.2.2->panel>=0.8.0->holoviews) (5.3.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh>=2.2.2->panel>=0.8.0->holoviews) (2.11.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh>=2.2.2->panel>=0.8.0->holoviews) (7.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh>=2.2.2->panel>=0.8.0->holoviews) (3.7.4.2)\n",
      "Requirement already satisfied: tornado>=5.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh>=2.2.2->panel>=0.8.0->holoviews) (6.0.4)\n",
      "Requirement already satisfied: packaging>=16.8 in /home/aditya/anaconda3/lib/python3.8/site-packages (from bokeh>=2.2.2->panel>=0.8.0->holoviews) (20.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from requests->panel>=0.8.0->holoviews) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/aditya/anaconda3/lib/python3.8/site-packages (from requests->panel>=0.8.0->holoviews) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from requests->panel>=0.8.0->holoviews) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aditya/anaconda3/lib/python3.8/site-packages (from requests->panel>=0.8.0->holoviews) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/aditya/anaconda3/lib/python3.8/site-packages (from Jinja2>=2.7->bokeh>=2.2.2->panel>=0.8.0->holoviews) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from packaging>=16.8->bokeh>=2.2.2->panel>=0.8.0->holoviews) (2.4.7)\n",
      "Requirement already satisfied: colorcet in /home/aditya/anaconda3/lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: param>=1.7.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from colorcet) (1.10.0)\n",
      "Requirement already satisfied: pyct>=0.4.4 in /home/aditya/anaconda3/lib/python3.8/site-packages (from colorcet) (0.4.6)\n",
      "Requirement already satisfied: pyLDAvis in /home/aditya/anaconda3/lib/python3.8/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (1.18.5)\n",
      "Requirement already satisfied: pytest in /home/aditya/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (5.4.3)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (0.34.2)\n",
      "Requirement already satisfied: future in /home/aditya/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (2.11.2)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (1.5.0)\n",
      "Requirement already satisfied: funcy in /home/aditya/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (1.15)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (0.16.0)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (1.0.5)\n",
      "Requirement already satisfied: numexpr in /home/aditya/anaconda3/lib/python3.8/site-packages (from pyLDAvis) (2.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis) (1.9.0)\n",
      "Requirement already satisfied: packaging in /home/aditya/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis) (20.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis) (8.4.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in /home/aditya/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/aditya/anaconda3/lib/python3.8/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pandas>=0.17.0->pyLDAvis) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/aditya/anaconda3/lib/python3.8/site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/aditya/anaconda3/lib/python3.8/site-packages (from packaging->pytest->pyLDAvis) (2.4.7)\n",
      "Requirement already satisfied: six in /home/aditya/anaconda3/lib/python3.8/site-packages (from packaging->pytest->pyLDAvis) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# for libraries not in docker image\n",
    "\n",
    "# installing libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install umap\n",
    "!{sys.executable} -m pip install missingno\n",
    "!{sys.executable} -m pip install rake_nltk\n",
    "!{sys.executable} -m pip install wordcloud\n",
    "!{sys.executable} -m pip install umap-learn\n",
    "!{sys.executable} -m pip install datashader \n",
    "!{sys.executable} -m pip install bokeh\n",
    "!{sys.executable} -m pip install holoviews\n",
    "!{sys.executable} -m pip install colorcet\n",
    "!{sys.executable} -m pip install pyLDAvis\n",
    "\n",
    "# importing installed libraries\n",
    "import umap\n",
    "import missingno\n",
    "from rake_nltk import Rake\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset into a dataframe\n",
    "df = pd.read_csv(\"dataset/USvideos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40949, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimensions of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40949 entries, 0 to 40948\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                40949 non-null  object\n",
      " 1   trending_date           40949 non-null  object\n",
      " 2   title                   40949 non-null  object\n",
      " 3   channel_title           40949 non-null  object\n",
      " 4   category_id             40949 non-null  int64 \n",
      " 5   publish_time            40949 non-null  object\n",
      " 6   tags                    40949 non-null  object\n",
      " 7   views                   40949 non-null  int64 \n",
      " 8   likes                   40949 non-null  int64 \n",
      " 9   dislikes                40949 non-null  int64 \n",
      " 10  comment_count           40949 non-null  int64 \n",
      " 11  thumbnail_link          40949 non-null  object\n",
      " 12  comments_disabled       40949 non-null  bool  \n",
      " 13  ratings_disabled        40949 non-null  bool  \n",
      " 14  video_error_or_removed  40949 non-null  bool  \n",
      " 15  description             40379 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# summary of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description    570\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of NaNs each column has.\n",
    "nans = pd.isnull(df).sum()\n",
    "nans[nans > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object    8\n",
       "int64     5\n",
       "bool      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grouping columns by datatype\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of numeric attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/aditya/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: regex in /home/aditya/anaconda3/lib/python3.8/site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in /home/aditya/anaconda3/lib/python3.8/site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: joblib in /home/aditya/anaconda3/lib/python3.8/site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: click in /home/aditya/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aditya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# installing libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install nltk\n",
    "\n",
    "# importing these libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/USvideos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with NA values\n",
    "df = df.dropna()\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove newlines \n",
    "df['description'] = df['description'].str.replace(r'\\\\t|\\\\n|\\\\r',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing URL's\n",
    "df['description'] = df['description'].str.replace(r'https?:\\/\\/\\S+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing HTML tags\n",
    "def remove_html_tags(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").text\n",
    "\n",
    "df['description'] = df['description'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove start/end spaces & lower-casing the result\n",
    "df['description'] = df['description'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuations\n",
    "df['description'] = df['description'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords removal\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')\n",
    "df['description'] = df['description'].apply(lambda text: ' '.join([word for word in str(text).split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for removing emoji's and emoticon's\n",
    "# u\"\\U00002500-\\U00002BEF\" -> chinese char\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  \n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  \n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "df['description'] = df['description'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing numbers\n",
    "df['description'] = df['description'].str.replace(r'\\d','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if cleaning resulted in nan value\n",
    "df['description'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>2644</td>\n",
       "      <td>5WUDfviiKRE</td>\n",
       "      <td>17.27.11</td>\n",
       "      <td>二贵摔跤 - tienghoa.net</td>\n",
       "      <td>Tina Nguyen</td>\n",
       "      <td>27</td>\n",
       "      <td>2011-03-01T04:14:08.000Z</td>\n",
       "      <td>hanyuqiao</td>\n",
       "      <td>16823</td>\n",
       "      <td>93</td>\n",
       "      <td>275</td>\n",
       "      <td>172</td>\n",
       "      <td>https://i.ytimg.com/vi/5WUDfviiKRE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>2869</td>\n",
       "      <td>5WUDfviiKRE</td>\n",
       "      <td>17.28.11</td>\n",
       "      <td>二贵摔跤 - tienghoa.net</td>\n",
       "      <td>Tina Nguyen</td>\n",
       "      <td>27</td>\n",
       "      <td>2011-03-01T04:14:08.000Z</td>\n",
       "      <td>hanyuqiao</td>\n",
       "      <td>21342</td>\n",
       "      <td>107</td>\n",
       "      <td>312</td>\n",
       "      <td>201</td>\n",
       "      <td>https://i.ytimg.com/vi/5WUDfviiKRE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>3122</td>\n",
       "      <td>5WUDfviiKRE</td>\n",
       "      <td>17.29.11</td>\n",
       "      <td>二贵摔跤 - tienghoa.net</td>\n",
       "      <td>Tina Nguyen</td>\n",
       "      <td>27</td>\n",
       "      <td>2011-03-01T04:14:08.000Z</td>\n",
       "      <td>hanyuqiao</td>\n",
       "      <td>21762</td>\n",
       "      <td>108</td>\n",
       "      <td>312</td>\n",
       "      <td>203</td>\n",
       "      <td>https://i.ytimg.com/vi/5WUDfviiKRE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>3359</td>\n",
       "      <td>5WUDfviiKRE</td>\n",
       "      <td>17.30.11</td>\n",
       "      <td>二贵摔跤 - tienghoa.net</td>\n",
       "      <td>Tina Nguyen</td>\n",
       "      <td>27</td>\n",
       "      <td>2011-03-01T04:14:08.000Z</td>\n",
       "      <td>hanyuqiao</td>\n",
       "      <td>22535</td>\n",
       "      <td>108</td>\n",
       "      <td>312</td>\n",
       "      <td>203</td>\n",
       "      <td>https://i.ytimg.com/vi/5WUDfviiKRE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>3595</td>\n",
       "      <td>5WUDfviiKRE</td>\n",
       "      <td>17.01.12</td>\n",
       "      <td>二贵摔跤 - tienghoa.net</td>\n",
       "      <td>Tina Nguyen</td>\n",
       "      <td>27</td>\n",
       "      <td>2011-03-01T04:14:08.000Z</td>\n",
       "      <td>hanyuqiao</td>\n",
       "      <td>22695</td>\n",
       "      <td>108</td>\n",
       "      <td>312</td>\n",
       "      <td>203</td>\n",
       "      <td>https://i.ytimg.com/vi/5WUDfviiKRE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index     video_id trending_date                title channel_title  \\\n",
       "2592   2644  5WUDfviiKRE      17.27.11  二贵摔跤 - tienghoa.net   Tina Nguyen   \n",
       "2808   2869  5WUDfviiKRE      17.28.11  二贵摔跤 - tienghoa.net   Tina Nguyen   \n",
       "3055   3122  5WUDfviiKRE      17.29.11  二贵摔跤 - tienghoa.net   Tina Nguyen   \n",
       "3286   3359  5WUDfviiKRE      17.30.11  二贵摔跤 - tienghoa.net   Tina Nguyen   \n",
       "3517   3595  5WUDfviiKRE      17.01.12  二贵摔跤 - tienghoa.net   Tina Nguyen   \n",
       "\n",
       "      category_id              publish_time       tags  views  likes  \\\n",
       "2592           27  2011-03-01T04:14:08.000Z  hanyuqiao  16823     93   \n",
       "2808           27  2011-03-01T04:14:08.000Z  hanyuqiao  21342    107   \n",
       "3055           27  2011-03-01T04:14:08.000Z  hanyuqiao  21762    108   \n",
       "3286           27  2011-03-01T04:14:08.000Z  hanyuqiao  22535    108   \n",
       "3517           27  2011-03-01T04:14:08.000Z  hanyuqiao  22695    108   \n",
       "\n",
       "      dislikes  comment_count                                  thumbnail_link  \\\n",
       "2592       275            172  https://i.ytimg.com/vi/5WUDfviiKRE/default.jpg   \n",
       "2808       312            201  https://i.ytimg.com/vi/5WUDfviiKRE/default.jpg   \n",
       "3055       312            203  https://i.ytimg.com/vi/5WUDfviiKRE/default.jpg   \n",
       "3286       312            203  https://i.ytimg.com/vi/5WUDfviiKRE/default.jpg   \n",
       "3517       312            203  https://i.ytimg.com/vi/5WUDfviiKRE/default.jpg   \n",
       "\n",
       "      comments_disabled  ratings_disabled  video_error_or_removed description  \n",
       "2592              False             False                   False              \n",
       "2808              False             False                   False              \n",
       "3055              False             False                   False              \n",
       "3286              False             False                   False              \n",
       "3517              False             False                   False              "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some Issue: \n",
    "#\n",
    "# After cleaning there are some entries that have an empty description or a very small one\n",
    "# Example:\n",
    "# https://www.youtube.com/watch?v=GcbsIv3QdFs - only has links in its description\n",
    "# Since we are removing all links, its description will be empty\n",
    "\n",
    "df[df['description'].str.len() <= 3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix\n",
    "df.loc[df['description'].str.len() < 3, ['description']] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['description'].str.len() == 4].head()\n",
    "df_new = df.drop_duplicates(subset=['video_id'], keep = 'last')\n",
    "df_new.reset_index(inplace=True)\n",
    "df_new = df_new.drop(['level_0', 'index'], axis=1)\n",
    "df_new_description = pd.DataFrame(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content_filter = df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the new column\n",
    "df_new['Key_words'] = \"\"\n",
    "\n",
    "for index, row in df_new.iterrows():\n",
    "    plot = row['description']\n",
    "    # instantiating Rake, by default it uses english stopwords from NLTK\n",
    "    # and discards all puntuation characters as well\n",
    "    r = Rake()\n",
    "\n",
    "    # extracting the words by passing the text\n",
    "    r.extract_keywords_from_text(plot)\n",
    "\n",
    "    # getting the dictionary whith key words as keys and their scores as values\n",
    "    key_words_dict_scores = r.get_word_degrees()\n",
    "    # assigning the key words to the new column for the corresponding video title\n",
    "    df_new['Key_words'][index] = list(key_words_dict_scores.keys())\n",
    "    \n",
    "# dropping the description column\n",
    "df_new.drop(columns = ['description'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop_duplicates(subset=['video_id'], keep = 'last')\n",
    "df_new.reset_index(inplace=True)\n",
    "df_title_channel_title = pd.DataFrame(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>Key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9wRQljFNDW8</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...</td>\n",
       "      <td>NFL</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-11-13T02:05:26.000Z</td>\n",
       "      <td>NFL|\"Football\"|\"offense\"|\"defense\"|\"afc\"|\"nfc\"...</td>\n",
       "      <td>81377</td>\n",
       "      <td>655</td>\n",
       "      <td>25</td>\n",
       "      <td>177</td>\n",
       "      <td>https://i.ytimg.com/vi/9wRQljFNDW8/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[new, england, patriots, returner, dion, lewis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Om_zGhJLZ5U</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>TL;DW - Every DCEU Movie Before Justice League</td>\n",
       "      <td>Screen Junkies</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-12T18:00:03.000Z</td>\n",
       "      <td>screenjunkies|\"screen junkies\"|\"sj news\"|\"hone...</td>\n",
       "      <td>288922</td>\n",
       "      <td>7515</td>\n",
       "      <td>792</td>\n",
       "      <td>2111</td>\n",
       "      <td>https://i.ytimg.com/vi/Om_zGhJLZ5U/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[justice, league, approaching, fast, rewatched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>goP4Z5wyOlM</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Iraq-Iran earthquake: Deadly tremor hits borde...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-12T21:16:40.000Z</td>\n",
       "      <td>bbc|\"bbc news\"|\"news\"|\"iran\"|\"iran news\"|\"iraq...</td>\n",
       "      <td>34785</td>\n",
       "      <td>308</td>\n",
       "      <td>26</td>\n",
       "      <td>413</td>\n",
       "      <td>https://i.ytimg.com/vi/goP4Z5wyOlM/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[strong, magnitude, earthquake, rattled, north...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8NHA23f7LvU</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Jason Momoa Wows Hugh Grant With Some Dothraki...</td>\n",
       "      <td>The Graham Norton Show</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-10T19:06:23.000Z</td>\n",
       "      <td>Graham Norton|\"Graham Norton Show Official\"|\"E...</td>\n",
       "      <td>1496225</td>\n",
       "      <td>16116</td>\n",
       "      <td>236</td>\n",
       "      <td>605</td>\n",
       "      <td>https://i.ytimg.com/vi/8NHA23f7LvU/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[think, sarah, millican, excited, subscribe, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>IE-xepGLVt8</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Mayo Clinic's first face transplant patient me...</td>\n",
       "      <td>Mayo Clinic</td>\n",
       "      <td>28</td>\n",
       "      <td>2017-11-10T12:04:17.000Z</td>\n",
       "      <td>Mayo Clinic|\"Health Care (Issue)\"|\"Healthcare ...</td>\n",
       "      <td>237307</td>\n",
       "      <td>1896</td>\n",
       "      <td>74</td>\n",
       "      <td>260</td>\n",
       "      <td>https://i.ytimg.com/vi/IE-xepGLVt8/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[one, half, years, surgery, transformed, life,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     video_id trending_date  \\\n",
       "0      0  9wRQljFNDW8      17.14.11   \n",
       "1      1  Om_zGhJLZ5U      17.14.11   \n",
       "2      2  goP4Z5wyOlM      17.14.11   \n",
       "3      3  8NHA23f7LvU      17.14.11   \n",
       "4      4  IE-xepGLVt8      17.14.11   \n",
       "\n",
       "                                               title           channel_title  \\\n",
       "0  Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...                     NFL   \n",
       "1     TL;DW - Every DCEU Movie Before Justice League          Screen Junkies   \n",
       "2  Iraq-Iran earthquake: Deadly tremor hits borde...                BBC News   \n",
       "3  Jason Momoa Wows Hugh Grant With Some Dothraki...  The Graham Norton Show   \n",
       "4  Mayo Clinic's first face transplant patient me...             Mayo Clinic   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           17  2017-11-13T02:05:26.000Z   \n",
       "1            1  2017-11-12T18:00:03.000Z   \n",
       "2           25  2017-11-12T21:16:40.000Z   \n",
       "3           24  2017-11-10T19:06:23.000Z   \n",
       "4           28  2017-11-10T12:04:17.000Z   \n",
       "\n",
       "                                                tags    views  likes  \\\n",
       "0  NFL|\"Football\"|\"offense\"|\"defense\"|\"afc\"|\"nfc\"...    81377    655   \n",
       "1  screenjunkies|\"screen junkies\"|\"sj news\"|\"hone...   288922   7515   \n",
       "2  bbc|\"bbc news\"|\"news\"|\"iran\"|\"iran news\"|\"iraq...    34785    308   \n",
       "3  Graham Norton|\"Graham Norton Show Official\"|\"E...  1496225  16116   \n",
       "4  Mayo Clinic|\"Health Care (Issue)\"|\"Healthcare ...   237307   1896   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0        25            177  https://i.ytimg.com/vi/9wRQljFNDW8/default.jpg   \n",
       "1       792           2111  https://i.ytimg.com/vi/Om_zGhJLZ5U/default.jpg   \n",
       "2        26            413  https://i.ytimg.com/vi/goP4Z5wyOlM/default.jpg   \n",
       "3       236            605  https://i.ytimg.com/vi/8NHA23f7LvU/default.jpg   \n",
       "4        74            260  https://i.ytimg.com/vi/IE-xepGLVt8/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                           Key_words  \n",
       "0  [new, england, patriots, returner, dion, lewis...  \n",
       "1  [justice, league, approaching, fast, rewatched...  \n",
       "2  [strong, magnitude, earthquake, rattled, north...  \n",
       "3  [think, sarah, millican, excited, subscribe, w...  \n",
       "4  [one, half, years, surgery, transformed, life,...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(['video_id','trending_date','category_id','publish_time','tags','views','likes','dislikes','comment_count','thumbnail_link','comments_disabled','ratings_disabled','video_error_or_removed'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>Key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...</td>\n",
       "      <td>NFL</td>\n",
       "      <td>[new, england, patriots, returner, dion, lewis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TL;DW - Every DCEU Movie Before Justice League</td>\n",
       "      <td>Screen Junkies</td>\n",
       "      <td>[justice, league, approaching, fast, rewatched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iraq-Iran earthquake: Deadly tremor hits borde...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>[strong, magnitude, earthquake, rattled, north...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jason Momoa Wows Hugh Grant With Some Dothraki...</td>\n",
       "      <td>The Graham Norton Show</td>\n",
       "      <td>[think, sarah, millican, excited, subscribe, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mayo Clinic's first face transplant patient me...</td>\n",
       "      <td>Mayo Clinic</td>\n",
       "      <td>[one, half, years, surgery, transformed, life,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>BTS Plays With Puppies While Answering Fan Que...</td>\n",
       "      <td>BuzzFeed Celeb</td>\n",
       "      <td>[bts, pps, puppies, adorable, provided, vander...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6250</th>\n",
       "      <td>The Cat Who Caught the Laser</td>\n",
       "      <td>AaronsAnimals</td>\n",
       "      <td>[cat, caught, laser, aarons, animals]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6251</th>\n",
       "      <td>I GAVE SAFIYA NYGAARD A PERFECT HAIR MAKEOVER ...</td>\n",
       "      <td>Brad Mondo</td>\n",
       "      <td>[much, fun, transforming, safiyas, hair, video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>How Black Panther Should Have Ended</td>\n",
       "      <td>How It Should Have Ended</td>\n",
       "      <td>[black, panther, endedwatch, hishes, hishe, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>Official Call of Duty®: Black Ops 4 — Multipla...</td>\n",
       "      <td>Call of Duty</td>\n",
       "      <td>[call, duty, black, ops, multiplayer, raises, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6254 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...   \n",
       "1        TL;DW - Every DCEU Movie Before Justice League   \n",
       "2     Iraq-Iran earthquake: Deadly tremor hits borde...   \n",
       "3     Jason Momoa Wows Hugh Grant With Some Dothraki...   \n",
       "4     Mayo Clinic's first face transplant patient me...   \n",
       "...                                                 ...   \n",
       "6249  BTS Plays With Puppies While Answering Fan Que...   \n",
       "6250                       The Cat Who Caught the Laser   \n",
       "6251  I GAVE SAFIYA NYGAARD A PERFECT HAIR MAKEOVER ...   \n",
       "6252                How Black Panther Should Have Ended   \n",
       "6253  Official Call of Duty®: Black Ops 4 — Multipla...   \n",
       "\n",
       "                 channel_title  \\\n",
       "0                          NFL   \n",
       "1               Screen Junkies   \n",
       "2                     BBC News   \n",
       "3       The Graham Norton Show   \n",
       "4                  Mayo Clinic   \n",
       "...                        ...   \n",
       "6249            BuzzFeed Celeb   \n",
       "6250             AaronsAnimals   \n",
       "6251                Brad Mondo   \n",
       "6252  How It Should Have Ended   \n",
       "6253              Call of Duty   \n",
       "\n",
       "                                              Key_words  \n",
       "0     [new, england, patriots, returner, dion, lewis...  \n",
       "1     [justice, league, approaching, fast, rewatched...  \n",
       "2     [strong, magnitude, earthquake, rattled, north...  \n",
       "3     [think, sarah, millican, excited, subscribe, w...  \n",
       "4     [one, half, years, surgery, transformed, life,...  \n",
       "...                                                 ...  \n",
       "6249  [bts, pps, puppies, adorable, provided, vander...  \n",
       "6250              [cat, caught, laser, aarons, animals]  \n",
       "6251  [much, fun, transforming, safiyas, hair, video...  \n",
       "6252  [black, panther, endedwatch, hishes, hishe, th...  \n",
       "6253  [call, duty, black, ops, multiplayer, raises, ...  \n",
       "\n",
       "[6254 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a bag of words by joining the words present in the title, channel_title and key_words field.\n",
    "df_new['bag_of_words'] = ''\n",
    "columns = df_new.columns\n",
    "for index, row in df_new.iterrows():\n",
    "    words = ''\n",
    "    for col in columns:\n",
    "        if col != 'channel_title':\n",
    "            words = words + ''.join(row[col])+ ' '\n",
    "        else:\n",
    "            words = words + row[col]+ ' '\n",
    "    df_new['bag_of_words'][index] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>Key_words</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...</td>\n",
       "      <td>NFL</td>\n",
       "      <td>[new, england, patriots, returner, dion, lewis...</td>\n",
       "      <td>Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TL;DW - Every DCEU Movie Before Justice League</td>\n",
       "      <td>Screen Junkies</td>\n",
       "      <td>[justice, league, approaching, fast, rewatched...</td>\n",
       "      <td>TL;DW - Every DCEU Movie Before Justice League...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iraq-Iran earthquake: Deadly tremor hits borde...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>[strong, magnitude, earthquake, rattled, north...</td>\n",
       "      <td>Iraq-Iran earthquake: Deadly tremor hits borde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jason Momoa Wows Hugh Grant With Some Dothraki...</td>\n",
       "      <td>The Graham Norton Show</td>\n",
       "      <td>[think, sarah, millican, excited, subscribe, w...</td>\n",
       "      <td>Jason Momoa Wows Hugh Grant With Some Dothraki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mayo Clinic's first face transplant patient me...</td>\n",
       "      <td>Mayo Clinic</td>\n",
       "      <td>[one, half, years, surgery, transformed, life,...</td>\n",
       "      <td>Mayo Clinic's first face transplant patient me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>BTS Plays With Puppies While Answering Fan Que...</td>\n",
       "      <td>BuzzFeed Celeb</td>\n",
       "      <td>[bts, pps, puppies, adorable, provided, vander...</td>\n",
       "      <td>BTS Plays With Puppies While Answering Fan Que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6250</th>\n",
       "      <td>The Cat Who Caught the Laser</td>\n",
       "      <td>AaronsAnimals</td>\n",
       "      <td>[cat, caught, laser, aarons, animals]</td>\n",
       "      <td>The Cat Who Caught the Laser AaronsAnimals cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6251</th>\n",
       "      <td>I GAVE SAFIYA NYGAARD A PERFECT HAIR MAKEOVER ...</td>\n",
       "      <td>Brad Mondo</td>\n",
       "      <td>[much, fun, transforming, safiyas, hair, video...</td>\n",
       "      <td>I GAVE SAFIYA NYGAARD A PERFECT HAIR MAKEOVER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>How Black Panther Should Have Ended</td>\n",
       "      <td>How It Should Have Ended</td>\n",
       "      <td>[black, panther, endedwatch, hishes, hishe, th...</td>\n",
       "      <td>How Black Panther Should Have Ended How It Sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>Official Call of Duty®: Black Ops 4 — Multipla...</td>\n",
       "      <td>Call of Duty</td>\n",
       "      <td>[call, duty, black, ops, multiplayer, raises, ...</td>\n",
       "      <td>Official Call of Duty®: Black Ops 4 — Multipla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6254 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...   \n",
       "1        TL;DW - Every DCEU Movie Before Justice League   \n",
       "2     Iraq-Iran earthquake: Deadly tremor hits borde...   \n",
       "3     Jason Momoa Wows Hugh Grant With Some Dothraki...   \n",
       "4     Mayo Clinic's first face transplant patient me...   \n",
       "...                                                 ...   \n",
       "6249  BTS Plays With Puppies While Answering Fan Que...   \n",
       "6250                       The Cat Who Caught the Laser   \n",
       "6251  I GAVE SAFIYA NYGAARD A PERFECT HAIR MAKEOVER ...   \n",
       "6252                How Black Panther Should Have Ended   \n",
       "6253  Official Call of Duty®: Black Ops 4 — Multipla...   \n",
       "\n",
       "                 channel_title  \\\n",
       "0                          NFL   \n",
       "1               Screen Junkies   \n",
       "2                     BBC News   \n",
       "3       The Graham Norton Show   \n",
       "4                  Mayo Clinic   \n",
       "...                        ...   \n",
       "6249            BuzzFeed Celeb   \n",
       "6250             AaronsAnimals   \n",
       "6251                Brad Mondo   \n",
       "6252  How It Should Have Ended   \n",
       "6253              Call of Duty   \n",
       "\n",
       "                                              Key_words  \\\n",
       "0     [new, england, patriots, returner, dion, lewis...   \n",
       "1     [justice, league, approaching, fast, rewatched...   \n",
       "2     [strong, magnitude, earthquake, rattled, north...   \n",
       "3     [think, sarah, millican, excited, subscribe, w...   \n",
       "4     [one, half, years, surgery, transformed, life,...   \n",
       "...                                                 ...   \n",
       "6249  [bts, pps, puppies, adorable, provided, vander...   \n",
       "6250              [cat, caught, laser, aarons, animals]   \n",
       "6251  [much, fun, transforming, safiyas, hair, video...   \n",
       "6252  [black, panther, endedwatch, hishes, hishe, th...   \n",
       "6253  [call, duty, black, ops, multiplayer, raises, ...   \n",
       "\n",
       "                                           bag_of_words  \n",
       "0     Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...  \n",
       "1     TL;DW - Every DCEU Movie Before Justice League...  \n",
       "2     Iraq-Iran earthquake: Deadly tremor hits borde...  \n",
       "3     Jason Momoa Wows Hugh Grant With Some Dothraki...  \n",
       "4     Mayo Clinic's first face transplant patient me...  \n",
       "...                                                 ...  \n",
       "6249  BTS Plays With Puppies While Answering Fan Que...  \n",
       "6250  The Cat Who Caught the Laser AaronsAnimals cat...  \n",
       "6251  I GAVE SAFIYA NYGAARD A PERFECT HAIR MAKEOVER ...  \n",
       "6252  How Black Panther Should Have Ended How It Sho...  \n",
       "6253  Official Call of Duty®: Black Ops 4 — Multipla...  \n",
       "\n",
       "[6254 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...\n",
       "1       TL;DW - Every DCEU Movie Before Justice League\n",
       "2    Iraq-Iran earthquake: Deadly tremor hits borde...\n",
       "3    Jason Momoa Wows Hugh Grant With Some Dothraki...\n",
       "4    Mayo Clinic's first face transplant patient me...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating and generating the count matrix\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(df_new['bag_of_words'])\n",
    "# creating a Series for the video titles so they are associated to an ordered numerical\n",
    "# we will use this list later to match the indices\n",
    "indices = pd.Series(df_new['title'])\n",
    "indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.05129892],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.05129892,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating the cosine similarity matrix.\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in video title as input and returns the top 10 recommended videos based on the similarity scores calculated.\n",
    "def recommendations(title, cosine_sim = cosine_sim):\n",
    "    \n",
    "    recommended_movies = []\n",
    "    \n",
    "    # gettin the index of the video title that matches the title given as argument to this method.\n",
    "    idx = indices[indices == title].index[0]\n",
    "\n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar videos\n",
    "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
    "    \n",
    "    top_10_indexes_scores = list(score_series.iloc[1:11])\n",
    "    \n",
    "    # populating the list with the titles of the best 10 matching videos\n",
    "    index = 0\n",
    "    for i in top_10_indexes:\n",
    "        recommended_movies.append(list(df_new['title'])[i]+\": \"+str(top_10_indexes_scores[index]))\n",
    "        index+=1\n",
    "        \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Official Call of Duty®: Black Ops 4 Teaser: 0.8346223261119858',\n",
       " \"Eagles' Home Radio Call of the Last Play of Super Bowl 52 | NFL Highlights: 0.31578947368421045\",\n",
       " 'Map of Biology: 0.30588764516074896',\n",
       " 'LIFE OF THE PARTY - Official Trailer 1: 0.29019050004400465',\n",
       " 'Welcome to the Official Class of 2018 Inductees: 0.2867696673382022',\n",
       " 'The Week Of | Official Trailer [HD] | Netflix: 0.27668578554642986',\n",
       " \"Rise of the TMNT Official Live Stream Character Art Reveal ft. Andre 'Black Nerd' & Kevin Eastman: 0.27036903521793754\",\n",
       " 'Troy: Fall Of A City | Official Trailer [HD] | Netflix: 0.26490647141300877',\n",
       " 'SICARIO, Day of the Soldado - Official Trailer (HD): 0.26490647141300877',\n",
       " 'Irelia: The Blade Dancer | Champion Trailer - League of Legends: 0.26315789473684204']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations('Official Call of Duty®: Black Ops 4 — Multiplayer Reveal Trailer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Camila Cabello, Daddy Yankee - Havana (Remix - Audio): 0.4216370213557839',\n",
       " 'Camila Cabello - Live from Youtube: 0.3651483716701108',\n",
       " 'Camila Cabello - Real Friends (Audio): 0.3585685828003181',\n",
       " 'Camila Cabello - Never Be The Same: 0.3508232077228117',\n",
       " 'Camila Cabello - Never Be the Same: 0.33541019662496846',\n",
       " \"Camila Cabello - Something's Gotta Give (Audio): 0.33541019662496846\",\n",
       " 'Made in Miami (Artist Spotlight Story) - Camila Cabello: 0.3265986323710904',\n",
       " 'Camila Cabello - Never Be the Same (Audio): 0.31622776601683794',\n",
       " 'Camila Cabello - Havana ft. Miranda Sings (Tana Mongeau Parody): 0.31622776601683794',\n",
       " 'HAVANA - CAMILA CABELLO (English + Spanish Cover): 0.31622776601683794']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations('Camila Cabello - Havana (Vertical Video) ft. Young Thug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How to Make MAGIC SAND: 0.6390096504226939',\n",
       " 'How To Make a Mega Metal Foundry: 0.6092717958449424',\n",
       " 'How To Make an Ocarina of Time IRL: 0.5962847939999439',\n",
       " 'Make a Glowing Announcement Board: 0.4811252243246882',\n",
       " 'GLOW Slime: 0.4364357804719848',\n",
       " 'How Does Smoke Behave in a Vacuum?: 0.4351941398892446',\n",
       " 'What Are the Chemicals In Our Bread | How to Make Everything: 0.4124789556921528',\n",
       " 'RAT TRAP Trebuchet: 0.408248290463863',\n",
       " 'Humongous Turkey Lollipop: 0.408248290463863',\n",
       " 'How to make the KELP SHAKE from Spongebob Squarepants!: 0.4003203845127179']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations('How To Make a Giant Flaming Vortex Fountain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Honest Trailers - Justice League: 0.4558423058385518',\n",
       " 'Honest Trailers - Every Wes Anderson Movie: 0.40201512610368484',\n",
       " 'Honest Trailers - Every Christopher Nolan Movie: 0.40201512610368484',\n",
       " 'Justice League - Movie Review: 0.3418817293789138',\n",
       " 'Justice League - Movie Review: 0.3418817293789138',\n",
       " 'Honest Trailers - The Emoji Movie: 0.3198010745334156',\n",
       " 'Screen Junkies 2017 Oscar Nominations: Our Academy Awards Picks: 0.30151134457776363',\n",
       " 'Honest Trailers - mother!: 0.2461829819586655',\n",
       " 'Honest Trailers - Jumanji: 0.2461829819586655',\n",
       " 'Justice League Bad: 0.2461829819586655']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations('TL;DW - Every DCEU Movie Before Justice League')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA on Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in video title as input and returns the top 10 recommended videos based on the similarity scores calculated for the lda\n",
    "def recommendations_lda(title, cosine_sim = cosine_sim):\n",
    "    \n",
    "    recommended_movies = []\n",
    "    \n",
    "    # gettin the index of the video title that matches the title given as argument to this method.\n",
    "    idx = indices[indices == title].index[0]\n",
    "\n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar videos\n",
    "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
    "    \n",
    "    top_10_indexes_scores = list(score_series.iloc[1:11])\n",
    "    \n",
    "    # populating the list with the titles of the best 10 matching videos\n",
    "    index = 0\n",
    "    for i in top_10_indexes:\n",
    "        recommended_movies.append(list(df_new['title'])[i]+\": \"+str(top_10_indexes_scores[index]))\n",
    "        index+=1\n",
    "        \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA model training on description text using tfdif vecortizer and UMAP results visualization based on the category and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "espn nfl youtube watch follow football nba mlb sportscenter scores\n",
      "\n",
      "Topic #1:\n",
      "guardian simons cat tshirt gq half itunes reddit interesting machine\n",
      "\n",
      "Topic #2:\n",
      "fbe feast fine react production credit brothers assistant coordinator cw\n",
      "\n",
      "Topic #3:\n",
      "tmz starr murrell spencer gilbert refinery geazy dan johns twice\n",
      "\n",
      "Topic #4:\n",
      "shots studios lele stocking anwar pons rudy jibawi hannah mancuso\n",
      "\n",
      "Topic #5:\n",
      "netflix music bravo members wwhl mythical entertainment follow watch million\n",
      "\n",
      "Topic #6:\n",
      "chappell warner production licensed buzzfeed images music idol buzzfeedvideo credits\n",
      "\n",
      "Topic #7:\n",
      "nail polish code broadcasts licensingstoryfulcom use lounge player bbc domino\n",
      "\n",
      "Topic #8:\n",
      "wwe mustsee wwecom month network crate waterjet match rest gordons\n",
      "\n",
      "Topic #9:\n",
      "refinery licensing licensingviralhogcom usage fort contact explosm century mcelfatrick fox\n",
      "\n",
      "Topic #10:\n",
      "nba conan yiay league refinery pass plays stories obrien highlights\n",
      "\n",
      "Topic #11:\n",
      "noggin life sins dude outer human gus smartphone body lauralee\n",
      "\n",
      "Topic #12:\n",
      "kimmel jimmy live tweets kimmels tatum channing lie mean jennifer\n",
      "\n",
      "Topic #13:\n",
      "tonight jimmy nbc fallon starring voice wired highlights sony vanity\n",
      "\n",
      "Topic #14:\n",
      "snl makeup palette cake powder cosmetics foundation beauty lip charles\n",
      "\n",
      "Topic #15:\n",
      "follow twitter video subscribe instagram facebook new late music videos\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    " \n",
    "# Helper function\n",
    "def print_topics(model, count_vectorizer):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i] for i in topic.argsort()[:-11:-1]]))\n",
    "        \n",
    "# Initialise the count vectorizer with the English stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# Fit and transform the processed description\n",
    "count_data_tfidf = tfidf_vectorizer.fit_transform(df_new_description['description'])        \n",
    "# Number of Topics\n",
    "number_topics = 16\n",
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics)\n",
    "lda.fit(count_data_tfidf)\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_tfidf = cosine_similarity(count_data_tfidf, count_data_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations after lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Official Call of Duty®: Black Ops 4 Teaser: 0.1622615784454197',\n",
       " 'Kendrick Lamar, SZA - All The Stars (Audio): 0.1342173880526215',\n",
       " 'Battlefield 5 Official Multiplayer Trailer: 0.10709087927840101',\n",
       " 'Obama arrives for jury duty at Daley Center: 0.10356914808524821',\n",
       " \"How Black Panther's Visual Effects Were Made | WIRED: 0.0912294465256556\",\n",
       " 'BLACK LIGHTNING - Series Premiere Review (Black Nerd): 0.08138965728908563',\n",
       " 'The Weeknd, Kendrick Lamar - Pray For Me (Audio): 0.07773996159439474',\n",
       " \"PLAYERUNKNOWN'S BATTLEGROUNDS - The Game Awards 2017 Gameplay Trailer: 0.0665184731819172\",\n",
       " \"Chris Stapleton - Tryin' To Untangle My Mind (Audio): 0.0647159006590976\",\n",
       " \"What New Yorkers Think Childish Gambino's “This Is America” Means | Genius News: 0.06080561830568116\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_lda('Official Call of Duty®: Black Ops 4 — Multiplayer Reveal Trailer',cosine_sim = cosine_sim_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Screen Junkies 2017 Oscar Nominations: Our Academy Awards Picks: 0.3770390884099942',\n",
       " 'Justice League - Movie Review: 0.2334326380969939',\n",
       " 'Honest Trailers - Batman Forever: 0.2137371262086743',\n",
       " 'Honest Trailers - Justice League: 0.19969919559453558',\n",
       " 'Honest Trailers - The Santa Clause: 0.1899689432008999',\n",
       " 'Justice League Could Lose WB Big Money - SJU: 0.18591306601347096',\n",
       " 'Honest Trailers - The Oscars (2018): 0.17452607774472406',\n",
       " 'Honest Trailers - Thor: Ragnarok: 0.16505314829804824',\n",
       " 'Honest Trailers - The Room: 0.16312768223515942',\n",
       " 'Honest Trailers - mother!: 0.16139923905898934']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_lda('TL;DW - Every DCEU Movie Before Justice League',cosine_sim = cosine_sim_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6254x42966 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 338308 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform \n",
    "# <pip uninstall umap-learn> (if not installed then skip this step)\n",
    "# <pip install umap-learn>\n",
    "# and then follow it\n",
    "# <pip install umap>\n",
    "import umap.umap_ as umap\n",
    "embedding = umap.UMAP(metric='hellinger').fit(count_data_tfidf)\n",
    "embedding_cv = umap.UMAP(metric='hellinger').fit(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UMAP(angular_rp_forest=True, metric='hellinger')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the category_id's as the labels\n",
    "category_ids = []\n",
    "for idx, document in enumerate(df_new_description['category_id']):\n",
    "        category_ids.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6254"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(category_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hover_df = pd.DataFrame(category_ids, columns=['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# umap plot on the processed descriptions after the application of fitting and transforming the descriptions for tfidf vectorizer.\n",
    "import umap.plot\n",
    "f = umap.plot.points(embedding,labels = hover_df['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# umap plot on the processed descriptions after the application of fitting and transforming the descriptions for count vectorizer.\n",
    "import umap.plot\n",
    "f = umap.plot.points(embedding_cv,labels = hover_df['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting umap connectivity for tfidf\n",
    "umap.plot.connectivity(embedding, show_points=True)\n",
    "#Plotting umap connectivity for Count vectorizer\n",
    "umap.plot.connectivity(embedding_cv, show_points=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_titles_channel = pd.DataFrame(df_title_channel_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_titles_channel = df_new_titles_channel[['category_id','title','channel_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UMAP INTERACTIVE FOR TFIDF\n",
    "p = umap.plot.interactive(embedding, labels=hover_df['category_id'], hover_data = df_new_titles_channel, point_size=2)\n",
    "umap.plot.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UMAP INTERACTIVE FOR COUNT VECTORIZER\n",
    "p = umap.plot.interactive(embedding_cv, labels=hover_df['category_id'], hover_data = df_new_titles_channel, point_size=2)\n",
    "umap.plot.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "from pyLDAvis import sklearn as sklearn_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "sklearn_lda.prepare(lda, count_data_tfidf, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_lda.prepare(lda, count_data_tfidf, tfidf_vectorizer,mds='tsne')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
